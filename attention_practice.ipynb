{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d870c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14e9d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key[0] @ query[0]: 32\n",
      "key @ query.T: [[  32  320]\n",
      " [ 320 3200]]\n",
      "\n",
      "key.T @ query: [[ 404  505  606]\n",
      " [ 808 1010 1212]\n",
      " [1212 1515 1818]]\n"
     ]
    }
   ],
   "source": [
    "# numpy playground \n",
    "data = [100, 200, 300]\n",
    "key = np.array([[1,2,3], [10, 20, 30]])\n",
    "query = np.array([[4,5,6], [40, 50, 60]])\n",
    "value = np.array([[7,8,9], [70, 80, 90]])\n",
    "\n",
    "print(\"key[0] @ query[0]:\", key[0] @ query[0])\n",
    "\n",
    "print(\"key @ query.T:\", key @ query.T)\n",
    "\n",
    "print(\"\\nkey.T @ query:\" , key.T @ query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39f78bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        self.data shape : (20,) ; \n",
      "        self.wquery shape : (20, 20) ; \n",
      "        self.wkey shape : (20, 20) ; \n",
      "        self.wvalue shape : (20, 20) ; \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# each node is a token\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        # the vector storoed at this node\n",
    "        self.data = np.random.rand(20)\n",
    "        \n",
    "        # weights governing how this node interacts with other nodes\n",
    "        # generates a 20x20 NumPy array filled with random numbers \n",
    "        self.wkey = np.random.randn(20,20)\n",
    "        self.wquery = np.random.randn(20,20)\n",
    "        self.wvalue = np.random.randn(20,20)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "        self.data shape : {self.data.shape} ; \n",
    "        self.wquery shape : {self.wquery.shape} ; \n",
    "        self.wkey shape : {self.wkey.shape} ; \n",
    "        self.wvalue shape : { self.wvalue.shape} ; \n",
    "        \"\"\"\n",
    "        \n",
    "    def key(self):\n",
    "        # @ Multiplication in NumPy\n",
    "        return self.wkey@self.data\n",
    "    \n",
    "    def query(self):\n",
    "        return self.wquery@self.data\n",
    "    \n",
    "    def value(self):\n",
    "        return self.wvalue@self.data\n",
    "    \n",
    "node = Node()\n",
    "print(node)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9335d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scores):\n",
    "    \"\"\"\n",
    "    Calculates the softmax function for a vector of scores.\n",
    "    Args:\n",
    "        scores: A NumPy array or list of scores.\n",
    "    Returns:\n",
    "        A NumPy array representing the softmax probabilities.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)  # Ensure scores is a NumPy array\n",
    "    exp_scores = np.exp(scores - np.max(scores))  # Subtract max for numerical stability\n",
    "    return exp_scores / np.sum(exp_scores)\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        # 5 nodes\n",
    "        self.nodes = [Node() for _ in range(5)]\n",
    "        \n",
    "        # 40 edegs, each edge is [node_index_from, node_index_to]\n",
    "        randi = lambda: np.random.randint(len(self.nodes))\n",
    "        self.edges = [[randi(), randi()] for _ in range(40)]\n",
    "        \n",
    "    def run(self):\n",
    "        updates = []\n",
    "        \n",
    "        # for each node in the graph\n",
    "        for i,n in enumerate(self.nodes):\n",
    "            \n",
    "            q = n.query()\n",
    "            \n",
    "            # find all edges that are input to this node n\n",
    "            inputs = [self.nodes[ifrom] for (ifrom, ito) in self.edges if ito == i]\n",
    "            if(len(inputs) == 0):\n",
    "                continue;\n",
    "                \n",
    "            keys = [m.key() for m in inputs]\n",
    "            \n",
    "            scores = [q @ k for k in keys]\n",
    "            \n",
    "            # calcuate the softmax for scores[] sum to 1\n",
    "            scores = softmax(scores)\n",
    "            \n",
    "            values = [m.value() for m in inputs]\n",
    "            update = sum([s*v for s, v in zip(scores, values)])\n",
    "            updates.append(update)\n",
    "        \n",
    "        # \n",
    "        for n, u in zip(self.nodes, updates):\n",
    "            n.data = n.data + u # residual connection\n",
    "            \n",
    "\n",
    "graph = Graph()\n",
    "graph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdb91829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  90\n",
      "everying in vocab \n",
      " !\"$%&'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYabcdefghijklmnopqrstuvwxyz~–—‘’“”…\n",
      "all encode: [56, 67, 67]\n",
      "decode: all\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "def read_file(file):\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "    return journal\n",
    "\n",
    "text = read_file(\"./oracle.txt\")\n",
    "\n",
    "# unique chars occur in the text \n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"vocab_size: \", vocab_size)\n",
    "print(\"everying in vocab\", ''.join(chars))\n",
    "\n",
    "# create mapping/dict between chars to integers\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "# encoder, take a string s, output a list of integers\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "# decoder, take a list of integers l, output a string\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(\"all encode:\", encode(\"all\"))\n",
    "print(\"decode:\", decode([56,67,67]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e10973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.type: <built-in method type of Tensor object at 0x115c39360>, data.shape: torch.Size([81716])\n",
      "data[:1000] tensor([45, 73, 56, 58, 67, 60, 26,  1, 35, 67, 67, 64, 74, 70, 69,  7, 74,  1,\n",
      "        52, 70, 80, 56, 62, 60,  1, 75, 70,  1, 49, 70, 61, 75, 78, 56, 73, 60,\n",
      "         1, 56, 69, 59,  1, 32, 60, 80, 70, 69, 59,  0, 55, 70, 76,  1, 58, 56,\n",
      "        69,  1, 67, 64, 74, 75, 60, 69,  1, 75, 70,  1, 75, 63, 64, 74,  1, 34,\n",
      "        60, 60, 71,  1, 34, 64, 77, 60,  1, 63, 60, 73, 60,  0,  0,  8, 44, 70,\n",
      "        75, 60, 26,  1, 78, 63, 64, 67, 60,  1, 39,  1, 76, 74, 76, 56, 67, 67,\n",
      "        80,  1, 76, 74, 60,  1, 68, 80,  1, 70, 78, 69,  1, 31, 39,  1, 77, 70,\n",
      "        64, 58, 60,  1, 75, 70,  1, 69, 56, 73, 73, 56, 75, 60,  1, 75, 63, 60,\n",
      "         1, 34, 60, 60, 71,  1, 34, 64, 77, 60, 12,  1, 39,  1, 63, 56, 77, 60,\n",
      "         1, 59, 60, 58, 64, 59, 60, 59,  1, 75, 70,  1, 76, 74, 60,  1, 56,  1,\n",
      "         3, 71, 73, 70, 61, 60, 74, 74, 64, 70, 69, 56, 67,  1, 31, 39,  1, 77,\n",
      "        70, 64, 58, 60,  3,  1, 56, 69, 59,  1, 76, 75, 64, 67, 64, 81, 60, 59,\n",
      "         1, 56,  1, 59, 64, 61, 61, 60, 73, 60, 69, 75,  1, 31, 39,  1, 75, 70,\n",
      "        70, 67,  1, 75, 63, 64, 74,  1, 75, 64, 68, 60, 14,  1, 39, 75,  7, 74,\n",
      "         1, 57, 60, 75, 75, 60, 73, 14,  9,  0,  0, 87, 53, 63, 80,  1, 59, 70,\n",
      "         1, 78, 60,  1, 59, 70,  1, 75, 63, 60, 74, 60,  1, 75, 63, 64, 69, 62,\n",
      "        74, 29,  1, 37, 60, 70, 73, 62, 60,  1, 43, 56, 67, 67, 70, 73, 80,  1,\n",
      "        74, 56, 64, 59,  1, 75, 63, 60,  1, 73, 60, 56, 74, 70, 69,  1, 63, 60,\n",
      "         1, 78, 56, 69, 75, 60, 59,  1, 75, 70,  1, 58, 67, 64, 68, 57,  1, 35,\n",
      "        77, 60, 73, 60, 74, 75,  1, 78, 56, 74,  1, 57, 60, 58, 56, 76, 74, 60,\n",
      "         1, 85, 64, 75,  7, 74,  1, 75, 63, 60, 73, 60, 86, 14,  1, 39,  1, 59,\n",
      "        70, 69,  7, 75,  1, 75, 63, 64, 69, 66,  1, 74, 70, 14,  1, 39,  1, 75,\n",
      "        63, 64, 69, 66,  1, 43, 56, 67, 67, 70, 73, 80,  1, 78, 56, 74,  1, 78,\n",
      "        73, 70, 69, 62, 14,  1, 39, 75,  7, 74,  1, 69, 70, 75,  1, 57, 60, 58,\n",
      "        56, 76, 74, 60,  1, 64, 75,  7, 74,  1, 75, 63, 60, 73, 60, 14,  1, 39,\n",
      "        75,  7, 74,  1, 57, 60, 58, 56, 76, 74, 60,  1, 78, 60,  7, 73, 60,  1,\n",
      "        75, 63, 60, 73, 60, 12,  1, 56, 69, 59,  1, 78, 60,  1, 78, 70, 69, 59,\n",
      "        60, 73,  1, 64, 61,  1, 78, 60,  1, 58, 56, 69,  1, 59, 70,  1, 64, 75,\n",
      "        14,  0,  0, 89, 39, 75,  7, 74,  1, 63, 56, 73, 59,  1, 61, 70, 73,  1,\n",
      "        68, 60,  1, 75, 70,  1, 72, 76, 64, 75,  1, 78, 63, 60, 69,  1, 39,  7,\n",
      "        68,  1, 67, 70, 74, 64, 69, 62, 84, 56, 69, 59,  1, 64, 75,  7, 74,  1,\n",
      "        63, 56, 73, 59,  1, 61, 70, 73,  1, 68, 60,  1, 75, 70,  1, 72, 76, 64,\n",
      "        75,  1, 78, 63, 60, 69,  1, 39,  7, 68,  1, 78, 64, 69, 69, 64, 69, 62,\n",
      "        14,  1, 39, 75,  7, 74,  1, 65, 76, 74, 75,  1, 63, 56, 73, 59,  1, 61,\n",
      "        70, 73,  1, 68, 60,  1, 75, 70,  1, 72, 76, 64, 75, 14,  1, 39,  7, 68,\n",
      "         1, 56, 59, 59, 64, 58, 75, 60, 59,  1, 75, 70,  1, 58, 70, 68, 71, 60,\n",
      "        75, 64, 69, 62, 14, 88,  0,  0, 13, 36, 73, 70, 68,  1, 75, 63, 60,  1,\n",
      "        57, 70, 70, 66,  1, 87, 50, 63, 60,  1, 32, 64, 67, 67, 64, 70, 69, 56,\n",
      "        64, 73, 60,  1, 56, 69, 59,  1, 75, 63, 60,  1, 43, 60, 58, 63, 56, 69,\n",
      "        64, 58, 26,  1, 38, 70, 78,  1, 42, 56, 73, 73, 80,  1, 35, 67, 67, 64,\n",
      "        74, 70, 69,  1, 56, 69, 59,  1, 56,  1, 33, 56, 73,  1, 43, 60, 58, 63,\n",
      "        56, 69, 64, 58,  1, 50, 60, 56, 68, 60, 59,  1, 76, 71,  1, 75, 70,  1,\n",
      "        53, 64, 69,  1, 49, 56, 64, 67, 64, 69, 62,  1, 74,  1, 37, 73, 60, 56,\n",
      "        75, 60, 74, 75,  1, 48, 56, 58, 60, 12,  1, 75, 63, 60,  1, 31, 68, 60,\n",
      "        73, 64, 58, 56, 74,  1, 33, 76, 71, 12,  1, 50, 78, 64, 58, 60, 88,  0,\n",
      "        50, 63, 64, 74,  1, 56, 59, 59, 64, 58, 75, 64, 70, 69,  1, 75, 70,  1,\n",
      "        58, 70, 68, 71, 60, 75, 64, 69, 62,  1, 60, 77, 60, 69,  1, 61, 70, 73,\n",
      "         1, 75, 63, 60,  1, 74, 56, 66, 60,  1, 70, 61,  1, 64, 75,  1, 63, 56,\n",
      "        74,  1, 74, 60, 73, 77, 60, 59,  1, 42, 56, 73, 73, 80,  1, 35, 67, 67,\n",
      "        64, 74, 70, 69, 12,  1, 75, 63, 60,  1, 33, 70, 13, 61, 70, 76, 69, 59,\n",
      "        60, 73,  1, 70, 61,  1, 45, 73, 56, 58, 67, 60, 12,  1, 60, 79, 58, 60,\n",
      "        60, 59, 64, 69, 62, 67, 80,  1, 78, 60, 67, 67,  1, 64, 69,  1, 67, 64,\n",
      "        61, 60, 14,  1, 35, 67, 67, 64, 74, 70, 69, 12,  1, 56, 67, 70, 69, 62,\n",
      "         1, 78, 64, 75, 63,  1, 32, 70, 57,  1, 43, 64, 69, 60, 73,  1, 56, 69,\n",
      "        59,  1, 35, 59,  1, 45, 56, 75, 60, 74, 12,  1, 74, 75, 56, 73, 75, 60,\n",
      "        59,  1, 45, 73, 56, 58, 67, 60,  1, 78])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(f\"data.type: {data.type}, data.shape: {data.shape}\", )\n",
    "print(\"data[:1000]\", data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6a4fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix.shape:  torch.Size([4])\n",
      "ix:  tensor([ 3147,  7054, 74286, 32000])\n",
      "input xb shape:  torch.Size([4, 8])\n",
      "tensor([[80,  1, 61, 64, 69, 56, 67, 67],\n",
      "        [70,  1, 62, 56, 77, 60,  1, 75],\n",
      "        [58, 56, 68, 60,  1, 56,  1, 74],\n",
      "        [56, 67, 67, 80,  1, 57, 60, 60]])\n",
      "target yb shape:  torch.Size([4, 8])\n",
      "tensor([[ 1, 61, 64, 69, 56, 67, 67, 80],\n",
      "        [ 1, 62, 56, 77, 60,  1, 75, 63],\n",
      "        [56, 68, 60,  1, 56,  1, 74, 60],\n",
      "        [67, 67, 80,  1, 57, 60, 60, 69]])\n"
     ]
    }
   ],
   "source": [
    "# building a batch of data\n",
    "# each batch of data (x, y)\n",
    "\n",
    "# how many independent chuncks of text we have in the batch\n",
    "# this is how many sequence we will process in parrell\n",
    "batch_size = 4 \n",
    "\n",
    "# max context length, predicting the 9th char in the sequence \n",
    "block_size = 8 \n",
    "\n",
    "# Get a random batch from data;\n",
    "# x: input ; y: desired ouput. y is behind x by 1 in time\n",
    "# both has shape: batch_size * block_size (B*T)\n",
    "def get_bacth(data):    \n",
    "    # generates a vector length of batch_size, each element is a random integer in the range [0, high).\n",
    "    # (batch_size,) creates a 1D tensor (a vector) with batch_size elements.\n",
    "    high = len(data) - block_size\n",
    "    ix = torch.randint(0, high, (batch_size,))\n",
    "    print(\"ix.shape: \", ix.shape)\n",
    "    print(\"ix: \", ix)\n",
    "    # wrong x = torch.stack(data[i:i+block_size] for i in ix)\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "    \n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "xb, yb = get_bacth(data)\n",
    "print(\"input xb shape: \", xb.shape)\n",
    "print(xb)\n",
    "print(\"target yb shape: \", yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59eb7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for batch: 0\n",
      " when input is: [80] ; output is: 1 \n",
      " when input is: [80, 1] ; output is: 61 \n",
      " when input is: [80, 1, 61] ; output is: 64 \n",
      " when input is: [80, 1, 61, 64] ; output is: 69 \n",
      " when input is: [80, 1, 61, 64, 69] ; output is: 56 \n",
      " when input is: [80, 1, 61, 64, 69, 56] ; output is: 67 \n",
      " when input is: [80, 1, 61, 64, 69, 56, 67] ; output is: 67 \n",
      " when input is: [80, 1, 61, 64, 69, 56, 67, 67] ; output is: 80 \n",
      "for batch: 1\n",
      " when input is: [70] ; output is: 1 \n",
      " when input is: [70, 1] ; output is: 62 \n",
      " when input is: [70, 1, 62] ; output is: 56 \n",
      " when input is: [70, 1, 62, 56] ; output is: 77 \n",
      " when input is: [70, 1, 62, 56, 77] ; output is: 60 \n",
      " when input is: [70, 1, 62, 56, 77, 60] ; output is: 1 \n",
      " when input is: [70, 1, 62, 56, 77, 60, 1] ; output is: 75 \n",
      " when input is: [70, 1, 62, 56, 77, 60, 1, 75] ; output is: 63 \n",
      "for batch: 2\n",
      " when input is: [58] ; output is: 56 \n",
      " when input is: [58, 56] ; output is: 68 \n",
      " when input is: [58, 56, 68] ; output is: 60 \n",
      " when input is: [58, 56, 68, 60] ; output is: 1 \n",
      " when input is: [58, 56, 68, 60, 1] ; output is: 56 \n",
      " when input is: [58, 56, 68, 60, 1, 56] ; output is: 1 \n",
      " when input is: [58, 56, 68, 60, 1, 56, 1] ; output is: 74 \n",
      " when input is: [58, 56, 68, 60, 1, 56, 1, 74] ; output is: 60 \n",
      "for batch: 3\n",
      " when input is: [56] ; output is: 67 \n",
      " when input is: [56, 67] ; output is: 67 \n",
      " when input is: [56, 67, 67] ; output is: 80 \n",
      " when input is: [56, 67, 67, 80] ; output is: 1 \n",
      " when input is: [56, 67, 67, 80, 1] ; output is: 57 \n",
      " when input is: [56, 67, 67, 80, 1, 57] ; output is: 60 \n",
      " when input is: [56, 67, 67, 80, 1, 57, 60] ; output is: 60 \n",
      " when input is: [56, 67, 67, 80, 1, 57, 60, 60] ; output is: 69 \n"
     ]
    }
   ],
   "source": [
    "# process the batch\n",
    "# each batch_i in the batch can be trained in parallel\n",
    "# time dimention can also be trained in parallel\n",
    "# the real \"batch size\" / \"parallel training\" is Batch_size * time (block_size) \n",
    "def process_batch(xb, yb):\n",
    "    for batch_i in range(0, batch_size): # batch dimension\n",
    "        print(f\"\"\"for batch: {batch_i}\"\"\")\n",
    "        for t in range(0, block_size): # time dimension\n",
    "            context = xb[batch_i, 0:t+1]\n",
    "            target = yb[batch_i,t]\n",
    "            print(f\"\"\" when input is: {context.tolist()} ; output is: {target.tolist()} \"\"\")\n",
    "            \n",
    "# the print out is the examples that model can learn from for a single batch xb, yb\n",
    "process_batch(xb, yb)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
